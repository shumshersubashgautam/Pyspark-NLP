{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9UV3qlUKtglhY6oGbke4M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shumshersubashgautam/Pyspark-NLP/blob/main/ViT_Image_Classification_Annotator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moWyjZiBISxk",
        "outputId": "cbcca883-88e2-443a-b02c-cf685d50412a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-04 14:19:57--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2023-05-04 14:19:57--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                     0%[                    ]       0  --.-KB/s               Installing PySpark 3.2.3 and Spark NLP 4.1.0\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 4.1.0\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-04 14:19:57 (51.0 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!wget https://setup.johnsnowlabs.com/colab.sh -O - | bash /dev/stdin -p 3.2.1 -s 4.1.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading Images\n",
        "!wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/images/images.zip"
      ],
      "metadata": {
        "id": "RacJPxdLIgJZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"images.zip\", \"images\", \"zip\")"
      ],
      "metadata": {
        "id": "Wv8CZYDAIl9Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start Spark Session\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "RUAZedsFIoMi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start()"
      ],
      "metadata": {
        "id": "AuxbuCxcIspu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = spark.read.format(\"image\").option(\"dropInvalid\", value = True).load(path=\"images/images/\")"
      ],
      "metadata": {
        "id": "V7OktMtnIuYf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline with ViTForImageClassification\n",
        "image_assembler = ImageAssembler() \\\n",
        "            .setInputCol(\"image\") \\\n",
        "            .setOutputCol(\"image_assembler\")\n",
        "\n",
        "image_classifier = ViTForImageClassification \\\n",
        "    .pretrained() \\\n",
        "    .setInputCols(\"image_assembler\") \\\n",
        "    .setOutputCol(\"class\")\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    image_assembler,\n",
        "    image_classifier,\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIhwY-BkIwXf",
        "outputId": "0707ffec-726f-4cf6-db52-4bb5e2f87111"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_classifier_vit_base_patch16_224 download started this may take some time.\n",
            "Approximate size to download 309.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(data_df)"
      ],
      "metadata": {
        "id": "ssmkzyctI0nZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_df = model.transform(data_df)\n",
        "image_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cPn92V2I3AW",
        "outputId": "44e1d25e-7dcb-4804-d037-638a7b4b587a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|               image|     image_assembler|               class|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|{file:///content/...|[{image, file:///...|[{category, 0, 5,...|\n",
            "|{file:///content/...|[{image, file:///...|[{category, 0, 11...|\n",
            "|{file:///content/...|[{image, file:///...|[{category, 0, 55...|\n",
            "|{file:///content/...|[{image, file:///...|[{category, 0, 2,...|\n",
            "|{file:///content/...|[{image, file:///...|[{category, 0, 24...|\n",
            "|{file:///content/...|[{image, file:///...|[{category, 0, 14...|\n",
            "|{file:///content/...|[{image, file:///...|[{category, 0, 7,...|\n",
            "|{file:///content/...|[{image, file:///...|[{category, 0, 8,...|\n",
            "|{file:///content/...|[{image, file:///...|[{category, 0, 6,...|\n",
            "|{file:///content/...|[{image, file:///...|[{category, 0, 1,...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Light Pipeline**"
      ],
      "metadata": {
        "id": "FClReJC1I84U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To use light pipeline in ViT transformer, need to use the new method fullAnnotateImage, which can receive 3 kind of inputs:\n",
        "\n",
        "# A path to a single image\n",
        "# A path to a list of images\n",
        "light_pipeline = LightPipeline(model)\n",
        "annotations_result = light_pipeline.fullAnnotateImage(\"images/images/hippopotamus.JPEG\")\n",
        "annotations_result[0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruGn-flvI4p4",
        "outputId": "185cdd99-920c-4c32-f664-792a5d8f1b92"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['image_assembler', 'class'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for result in annotations_result:\n",
        "  image_assembler = result['image_assembler'][0]\n",
        "  print(f\"annotator_type: {image_assembler.annotator_type}\")\n",
        "  print(f\"origin: {image_assembler.origin}\")\n",
        "  print(f\"height: {image_assembler.height}\")\n",
        "  print(f\"width: {image_assembler.width}\")\n",
        "  print(f\"nChannels: {image_assembler.nChannels}\")\n",
        "  print(f\"mode: {image_assembler.mode}\")\n",
        "  print(f\"result size: {str(len(image_assembler.result))}\")\n",
        "  print(f\"metadata: {image_assembler.metadata}\")\n",
        "  print(result['class'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNsAmvmxJHDR",
        "outputId": "c823963b-253f-4d10-cf5d-cfc2aabb0ce8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annotator_type: image\n",
            "origin: images/images/hippopotamus.JPEG\n",
            "height: 333\n",
            "width: 500\n",
            "nChannels: 3\n",
            "mode: 16\n",
            "result size: 499500\n",
            "metadata: Map()\n",
            "[Annotation(category, 0, 55, hippopotamus, hippo, river horse, Hippopotamus amphibius, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 7.2882756E-8, Some(beer glass) -> 9.0488925E-8, image -> 0, Some(damselfly) -> 1.9379786E-7, Some(turnstile) -> 6.8434524E-8, Some(cockroach, roach) -> 1.6622849E-7, height -> 333, Some(bulbul) -> 1.6930231E-7, Some(sea snake) -> 8.89582E-8, origin -> images/images/hippopotamus.JPEG, Some(mixing bowl) -> 1.2995402E-7, mode -> 16, None -> 1.3814622E-7, Some(whippet) -> 3.894023E-8, width -> 500, Some(buckle) -> 1.0061492E-7))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To send a list of images, we just difine a set of images\n",
        "images = [\"images/images/bluetick.jpg\", \"images/images/palace.JPEG\", \"images/images/hen.JPEG\"]\n",
        "annotations_result = light_pipeline.fullAnnotateImage(images)\n",
        "annotations_result[0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l46LcewJJBh",
        "outputId": "7d91d543-2012-4517-8ff1-6684878d79b6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['image_assembler', 'class'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for result in annotations_result:\n",
        "  print(result['class'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zamxOFZTJN5X",
        "outputId": "e6c398cc-b74f-4c0a-cc9a-5211878afdb6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Annotation(category, 0, 7, bluetick, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 1.3846728E-6, Some(beer glass) -> 1.1807944E-6, image -> 0, Some(damselfly) -> 3.6875622E-7, Some(turnstile) -> 2.023695E-6, Some(cockroach, roach) -> 6.2982855E-7, height -> 500, Some(bulbul) -> 5.417509E-7, Some(sea snake) -> 5.7421556E-7, origin -> images/images/bluetick.jpg, Some(mixing bowl) -> 5.4001305E-7, mode -> 16, None -> 4.5454306E-7, Some(whippet) -> 1.2101438E-6, width -> 333, Some(buckle) -> 1.1306514E-6))]\n",
            "[Annotation(category, 0, 5, palace, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 6.3918545E-5, Some(beer glass) -> 8.879939E-6, image -> 0, Some(damselfly) -> 9.565577E-6, Some(turnstile) -> 6.315168E-5, Some(cockroach, roach) -> 1.125408E-5, height -> 334, Some(bulbul) -> 3.321073E-5, Some(sea snake) -> 1.0886038E-5, origin -> images/images/palace.JPEG, Some(mixing bowl) -> 2.6202975E-5, mode -> 16, None -> 2.6134943E-5, Some(whippet) -> 1.3805137E-5, width -> 500, Some(buckle) -> 3.121459E-5))]\n",
            "[Annotation(category, 0, 2, hen, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 2.1663836E-5, Some(beer glass) -> 3.062036E-6, image -> 0, Some(damselfly) -> 5.8477954E-6, Some(turnstile) -> 1.8546416E-6, Some(cockroach, roach) -> 2.5356887E-6, height -> 375, Some(bulbul) -> 3.2049334E-6, Some(sea snake) -> 2.8824059E-6, origin -> images/images/hen.JPEG, Some(mixing bowl) -> 6.9148127E-6, mode -> 16, None -> 2.824775E-6, Some(whippet) -> 4.5998115E-7, width -> 500, Some(buckle) -> 1.6334545E-5))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BpsuyPEtJP7W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}